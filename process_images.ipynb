{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Processor\n",
    "The goal of this notebook is to create a model that can classify images of the following two classes:\n",
    "- Kaninchen\n",
    "- Feldhase\n",
    "\n",
    "To do so, the following steps are performed: \n",
    "First, the images are loaded and randomly augmented with each loading. This does not only make the model more robust, but it also helps to prevent the model from learning the images (known as overfitting). Part of the augmentation is the scaling of the images. We create a train, a validation, and a test data set.\n",
    "Second, \n",
    "\n",
    "The comments in this notebook are plenty and generated mostly using the help of artificial intelligence. This approach is chosen, as it enables both the developers and the users of this notebook to understand the code better."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52335692d14e9776"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3693b8f986328b26"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:05.979328Z",
     "start_time": "2024-01-10T15:27:05.955688Z"
    }
   },
   "id": "f942088f6822c409",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adjust the GPU memory growth dynamically"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1386b3984ac34736"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU') # Get the list of GPUs\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True) # enable tensorflow to allocate memory dynamically -> use only as much GPU memory as needed\n",
    "gpus"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:05.989877Z",
     "start_time": "2024-01-10T15:27:05.983184Z"
    }
   },
   "id": "150016df4048127"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') # Check if GPU is available"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:05.993099Z",
     "start_time": "2024-01-10T15:27:05.988449Z"
    }
   },
   "id": "b7cdfe5e88fb1c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load images into train/validation/test data, and apply data augmentation to artificially increase the size of the data set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c19d96e6b9493e62"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.src.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator instance with various data augmentation parameters\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         # Scale the images to values between 0 and 1\n",
    "    rotation_range=10,      # Randomly rotate images by up to 10 degrees\n",
    "    width_shift_range=0.1,  # Randomly shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1, # Randomly shift images vertically by up to 10%\n",
    "    shear_range=0.2,        # Shear transformation to tilt the image by up to 20%\n",
    "    zoom_range=0.2,         # Randomly zoom in on images by up to 20%\n",
    "    # horizontal_flip=True,   # Randomly flip images horizontally, does not make sense in or case\n",
    "    vertical_flip=False,    # No vertical flipping in this example\n",
    "    fill_mode='nearest'     # Fill in missing pixels with the nearest available pixel\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator( # No data augmentation for the validation and test data\n",
    "    rescale=1./255                 # Just perform the rescaling\n",
    ")\n",
    "\n",
    "# Load data and apply transformations\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    'photos',               # Load images from the 'photos' folder\n",
    "    target_size=(256, 256), # Resize the images to 256x256 pixels\n",
    "    batch_size=32,          # Load 32 images at a time\n",
    "    class_mode='binary')    # We have a binary classification problem (Kaninchen or Feldhase)\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "    'photos',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'photos',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:06.037912Z",
     "start_time": "2024-01-10T15:27:05.996258Z"
    }
   },
   "id": "3c5775b28d29e1ad",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f9cc0962bdb078"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# sequential means that the layers are stacked on top of each other leading to a feed forward neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Adding a convolutional layer to detect features in the images\n",
    "    \n",
    "    # 16 filters to detect 16 different features like edges, textures, structure etc.\n",
    "    # 3x3 kernel size to detect features in a 3x3 area\n",
    "    # 1 stride to move the kernel by 1 pixel\n",
    "    # relu activation function to introduce non-linearity\n",
    "    # input shape: height, width, colors/channels (RGB)\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3)), # output shape: 254x254x16 (width, height, features)\n",
    "\n",
    "    # Adding a max pooling layer to reduce the dimensionality of the data\n",
    "    # achieved by taking the maximum value of a 2x2 area as the representative value for that area\n",
    "    tf.keras.layers.MaxPool2D(), # output shape: 127x127x16\n",
    "    \n",
    "    # Adding more layers to continously learn more complex features\n",
    "    # Continouse learning of more complex features is achieved by increasing the number of filters\n",
    "    # A more compact representation of the data is achieved by reducing the kernel size continuously via max pooling\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), 1, activation='relu'), # output shape: 125x125x32\n",
    "    tf.keras.layers.MaxPool2D(), # output shape: 62x62x32\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), 1, activation='relu'), # output shape: 60x60x64\n",
    "    tf.keras.layers.MaxPooling2D(), # output shape: 30x30x64 (width, height, features)\n",
    "    \n",
    "    # Adding a flatten layer to transform the 2D data into a 1D vector\n",
    "    tf.keras.layers.Flatten(), # output shape: 57600\n",
    "    \n",
    "    # Adding a dense layer to learn the classification\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Adding the output layer to classify the images - either as a Kaninchen or as a Feldhase\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:06.106102Z",
     "start_time": "2024-01-10T15:27:06.041669Z"
    }
   },
   "id": "ac8960157002f51d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuring the neural network model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fe83a9ecd40dd4b"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# 'compile' configures the selected neural network model\n",
    "# 'adam' adapts the learning rate of each parameter individually, aiming to minimize the loss function (binary crossentropy in our case)\n",
    "# the metrics are used to measure the performance of the model\n",
    "model.compile(optimizer='adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T15:27:06.114943Z",
     "start_time": "2024-01-10T15:27:06.109721Z"
    }
   },
   "id": "5735edff61b2a4e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model using early stopping and a customized learning rate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa22a7757a8421b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 10s 693ms/step - loss: 0.8267 - accuracy: 0.4875 - val_loss: 0.6853 - val_accuracy: 0.5125\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 9s 674ms/step - loss: 0.6601 - accuracy: 0.6275 - val_loss: 0.6258 - val_accuracy: 0.6425\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 9s 700ms/step - loss: 0.6181 - accuracy: 0.6500 - val_loss: 0.5198 - val_accuracy: 0.7675\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 10s 778ms/step - loss: 0.5266 - accuracy: 0.7475 - val_loss: 0.4455 - val_accuracy: 0.8100\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 10s 709ms/step - loss: 0.4586 - accuracy: 0.7950 - val_loss: 0.3978 - val_accuracy: 0.8200\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 9s 712ms/step - loss: 0.4433 - accuracy: 0.7975 - val_loss: 0.4137 - val_accuracy: 0.8050\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 9s 677ms/step - loss: 0.4297 - accuracy: 0.8125 - val_loss: 0.3123 - val_accuracy: 0.8725\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 9s 690ms/step - loss: 0.3533 - accuracy: 0.8675 - val_loss: 0.2570 - val_accuracy: 0.8825\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 12s 910ms/step - loss: 0.3267 - accuracy: 0.8625 - val_loss: 0.2565 - val_accuracy: 0.8950\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 10s 743ms/step - loss: 0.3080 - accuracy: 0.8850 - val_loss: 0.3049 - val_accuracy: 0.8975\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 10s 807ms/step - loss: 0.2973 - accuracy: 0.8725 - val_loss: 0.2821 - val_accuracy: 0.8875\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 10s 738ms/step - loss: 0.3262 - accuracy: 0.8400 - val_loss: 0.3235 - val_accuracy: 0.8650\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 9s 729ms/step - loss: 0.3004 - accuracy: 0.8650 - val_loss: 0.2033 - val_accuracy: 0.9125\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9025"
     ]
    }
   ],
   "source": [
    "# Implementing early stopping to prevent overfitting\n",
    "# 'patience' is the number of epochs with no improvement after which training will be stopped\n",
    "# 'restore_best_weights' restores the weights from the epoch with the best value of the monitored quantity\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 'fit' trains the model\n",
    "# 'epochs' is the number of times the model is trained on the whole dataset\n",
    "hist = model.fit(train_set, validation_data=validation_set, epochs=50, callbacks=[early_stopping])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-10T15:27:06.114333Z"
    }
   },
   "id": "c23bfe63e3a4aa42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot the training and the validation accuracy, as well as the loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5c569326fdb0a4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and the validation accuracy and loss in one figure\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model accuracy and loss')\n",
    "plt.ylabel('Accuracy and loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(['Training accuracy', 'Validation accuracy', 'Training loss', 'Validation loss'], loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e4938f86e937cf82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model based on the test data\n",
    "test_loss, test_acc = model.evaluate(test_set, verbose=2) # verbose=2 to suppress the progress bar\n",
    "print(f'Test accuracy: {test_acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "271587a53471d18c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8f76ab9eba72595"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model as a TensorFlow SavedModel\n",
    "#model.save('model_99')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bc1c3296edc803f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9a69d96d3e908ad9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
